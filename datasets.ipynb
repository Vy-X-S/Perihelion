{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def read_jsonl(file_path, number_of_lines = 100):\n",
    "    \"\"\"\n",
    "    Reads a specified number of lines from a JSON Lines file and splits the data into train and test sets.\n",
    "\n",
    "    :param file_path: Path to the JSON Lines file.\n",
    "    :param number_of_lines: Number of lines to read from the file.\n",
    "    :return: DataFrame \n",
    "    \"\"\"\n",
    "    \n",
    "    # Read specified number of lines from file\n",
    "    with open(file_path) as file:\n",
    "        lines = [json.loads(next(file)) for _ in range(number_of_lines)]\n",
    "        \n",
    "    # Convert list of JSON objects to Pandas DF\n",
    "    data = pd.DataFrame(lines)\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = read_jsonl(\"dataset/grocery_fixed.jsonl\", 500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Preprocessing \n",
    "\n",
    "def pre_process(text):\n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # remove tags\n",
    "    text = re.sub(\"&lt;/?.*&gt;\",\" &lt;&gt; \", text)\n",
    "    \n",
    "    # remove special characters \n",
    "    text = re.sub(\"(\\\\d|\\\\W)+\",\" \", text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "data['text'] = data['title'] + \" \" + data['text']\n",
    "data['text'] = data['text'].apply(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key = lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\" Get feature names and tf-idf scores of top n items\"\"\"\n",
    "    sorted_items = sorted_items[:topn]\n",
    "    \n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    \n",
    "    for idx, score in sorted_items:\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    "    \n",
    "    results = {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]] = score_vals[idx]\n",
    "    \n",
    "    return results\n",
    "\n",
    "def get_stop_words(stop_file_path):\n",
    "    \"\"\"Load stop words\"\"\"\n",
    "    with open(stop_file_path, 'r', encoding='utf-8') as f:\n",
    "        stopwords = f.readlines()\n",
    "        stop_set = [m.strip() for m in stopwords]\n",
    "        return stop_set  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures\n",
    "from nltk.collocations import TrigramCollocationFinder, TrigramAssocMeasures\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def extract_keywords_for_product(data, asin, topn=10):\n",
    "    \"\"\"\n",
    "    Extract top n keywords for a specific product based on its reviews.\n",
    "    \n",
    "    :param data: The dataset containing reviews.\n",
    "    :param asin: The product identifier (e.g., ASIN) to extract keywords for.\n",
    "    :param topn: The number of top keywords to extract.\n",
    "    :return: A dictionary of top n keywords and their TF-IDF scores for the specified product.\n",
    "    \"\"\"\n",
    "    # Load set of stop words\n",
    "    stopwords = get_stop_words(\"dataset/stopwords.txt\")\n",
    "\n",
    "    # Initialize TF-IDF Vectorizer\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df=0.85, stop_words=stopwords, max_features=10000)\n",
    "\n",
    "    # Filter reviews for the specified product\n",
    "    product_data = data.loc[data['parent_asin'] == asin]\n",
    "    docs = product_data['text'].tolist()\n",
    "\n",
    "    # Compute TF-IDF matrix\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(docs)\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Sort items by TF-IDF score\n",
    "    sorted_items = sort_coo(tfidf_matrix.tocoo())\n",
    "\n",
    "    # Extract top n keywords\n",
    "    keywords = extract_topn_from_vector(feature_names, sorted_items, topn=topn)\n",
    "\n",
    "    return keywords\n",
    "def get_top_ngrams_for_product(reviews, topn=10, min_freq=3):\n",
    "    \"\"\"\n",
    "    Get the top bigrams and trigrams for a specific product's reviews.\n",
    "    \n",
    "    :param reviews: List of reviews for a specific product.\n",
    "    :param topn: Number of top n-grams to return.\n",
    "    :param min_freq: Minimum frequency for n-grams to be considered.\n",
    "    :return: A tuple containing lists of the top bigrams and trigrams.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Preprocess and tokenize reviews\n",
    "    tokenized_reviews = [word_tokenize(review) for review in reviews]\n",
    "    \n",
    "    # Flatten list of tokenized reviews into one list of words\n",
    "    all_words = [word for tokens in tokenized_reviews for word in tokens]\n",
    "    \n",
    "    # Instantiate collocation finders\n",
    "    bigram_finder = BigramCollocationFinder.from_words(all_words)\n",
    "    trigram_finder = TrigramCollocationFinder.from_words(all_words)\n",
    "    \n",
    "    # Apply frequency filter \n",
    "    bigram_finder.apply_freq_filter(min_freq)\n",
    "    trigram_finder.apply_freq_filter(min_freq)\n",
    "    \n",
    "    # Measures for calculating PMI\n",
    "    bigram_measures = BigramAssocMeasures()\n",
    "    trigram_measures = TrigramAssocMeasures()\n",
    "    \n",
    "    # Extract top n-grams with highest PMI \n",
    "    top_bigrams = bigram_finder.nbest(bigram_measures.pmi, topn)\n",
    "    top_trigrams = trigram_finder.nbest(trigram_measures.pmi, topn)\n",
    "    \n",
    "    return top_bigrams, top_trigrams\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parent_asin\n",
       "B00ESE0DC4    3443\n",
       "B01NAYX4S3    2269\n",
       "B0BZZWHKHQ    2256\n",
       "B0C396H8QB    1934\n",
       "B07VV7T465    1659\n",
       "              ... \n",
       "B07871X7S6       1\n",
       "B00E1ZMXFA       1\n",
       "B00IG8GP20       1\n",
       "B01LY8QGD1       1\n",
       "B091NC2LBC       1\n",
       "Name: count, Length: 135818, dtype: int64"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['parent_asin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product keywords: {'yummy': 0.919, 'works': 0.896, 'test': 1.0, 'price': 1.0, 'perfect': 1.0, 'love': 0.874, 'great': 0.882, 'good': 0.893, 'excellent': 0.917, 'bad': 1.0, 'salud': 0.961, 'nutrition': 0.954, 'disgusting': 0.946, 'flav': 0.941, 'terrible': 0.936, 'liked': 0.929, 'tasteful': 0.928, 'review': 0.913, 'nice': 0.894, 'light': 0.903, 'smoothie': 0.902, 'item': 0.9, 'awesome': 0.9, 'pricey': 0.895, 'supplement': 0.894, 'delicious': 0.888, 'loved': 0.877, 'vegan': 0.866, 'easy': 0.865, 'worst': 0.856, 'advertised': 0.853, 'everyday': 0.853, 'stevia': 0.85, 'matallic': 0.848, 'tasty': 0.845, 'mixed': 0.844, 'supergreenfood': 0.842}\n",
      "\n",
      "Top bigrams: [('sams', 'club'), ('college', 'student'), ('static', 'electricity'), ('trader', 'joe'), ('psyllium', 'husk'), ('game', 'changer'), ('flax', 'seed'), ('bowel', 'movements'), ('heavy', 'metals'), ('room', 'temperature'), ('crystal', 'light'), ('cider', 'vinegar'), ('fairly', 'priced'), ('chia', 'seeds'), ('citric', 'acid'), ('repeat', 'customer'), ('lawn', 'clippings'), ('grocery', 'store'), ('wan', 'na'), ('gon', 'na'), ('peanut', 'butter'), ('nutrient', 'dense'), ('ingredient', 'list'), ('maca', 'root'), ('lost', 'lbs'), ('lost', 'pounds'), ('placebo', 'effect'), ('non', 'gmo'), ('customer', 'service'), ('weight', 'loss'), ('acid', 'reflux'), ('oh', 'boy'), ('nutrient', 'profile'), ('raw', 'reserve'), ('picky', 'eater'), ('greek', 'yogurt'), ('vitamin', 'k'), ('pleasantly', 'surprised'), ('ground', 'flax'), ('asin', 'b'), ('yr', 'old'), ('immune', 'system'), ('fresh', 'squeezed'), ('plant', 'based'), ('long', 'term'), ('pre', 'workout'), ('amazon', 'prime'), ('gluten', 'free'), ('force', 'myself'), ('lose', 'weight')]\n",
      "\n",
      "Top trigrams: [('apple', 'cider', 'vinegar'), ('trader', 'joe', 's'), ('ended', 'up', 'throwing'), ('non', 'gmo', 'organic'), ('room', 'temperature', 'water'), ('farm', 'in', 'kansas'), ('year', 'old', 'son'), ('plant', 'based', 'protein'), ('worth', 'every', 'penny'), ('like', 'lawn', 'clippings'), ('are', 'gon', 'na'), ('smelled', 'like', 'fish'), ('great', 'customer', 'service'), ('m', 'gon', 'na'), ('placebo', 'effect', 'but'), ('gon', 'na', 'be'), ('blend', 'mg', 'organic'), ('subscribe', 'and', 'save'), ('exactly', 'as', 'described'), ('almost', 'threw', 'up'), ('goji', 'and', 'acai'), ('waste', 'your', 'money'), ('unsweetened', 'vanilla', 'almond'), ('came', 'as', 'described'), ('a', 'repeat', 'customer'), ('some', 'ice', 'cubes'), ('health', 'food', 'store'), ('of', 'asin', 'b'), ('unsweetened', 'almond', 'milk'), ('garden', 'of', 'life'), ('a', 'picky', 'eater'), ('tried', 'several', 'times'), ('figure', 'out', 'how'), ('my', 'husband', 'uses'), ('on', 'its', 'own'), ('no', 'matter', 'how'), ('not', 'gon', 'na'), ('a', 'placebo', 'effect'), ('the', 'ingredient', 'list'), ('t', 'normally', 'consume'), ('kale', 'or', 'spinach'), ('handful', 'of', 'spinach'), ('like', 'fish', 'food'), ('an', 'hour', 'after'), ('about', 'an', 'hour'), ('my', 'immune', 'system'), ('are', 'sourced', 'from'), ('force', 'myself', 'to'), ('feel', 'alive', 'again'), ('will', 'be', 'repurchasing')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "asin = \"B0BZZWHKHQ\"\n",
    "topn = 50\n",
    "\n",
    "product_keywords = extract_keywords_for_product(data, asin, topn=topn)\n",
    "\n",
    "product_reviews = data.loc[data['parent_asin'] == asin]['text'].tolist()\n",
    "top_bigrams, top_trigrams = get_top_ngrams_for_product(product_reviews, topn=topn, min_freq=3)\n",
    "\n",
    "print(f\"Product keywords: {product_keywords}\\n\")\n",
    "print(f\"Top bigrams: {top_bigrams}\\n\")\n",
    "print(f\"Top trigrams: {top_trigrams}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
